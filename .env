# Kiro Gateway - 环境配置
# 复制此文件到 .env 并填写你的配置值

# ===========================================
# 必需配置 (REQUIRED)
# ===========================================

# 代理服务器密码 - 用于保护你的网关服务器
# 这不是从任何地方获取的 token - 你自己设定！
# 连接到网关时使用相同的值作为 api_key
# 示例: "my-super-secret-password-123" 或任何安全字符串
# Password to protect YOUR proxy server
PROXY_API_KEY="sk-36fc0c8dc2e2e7f8c02800284deac614250fecce86fea6cd"

# ===========================================
# 选项 1: Kiro IDE 凭证文件 (JSON file)
# ===========================================

# Kiro IDE 凭证 JSON 文件路径
# Path to JSON credentials file from Kiro IDE
# KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# ===========================================
# 选项 2: Kiro IDE 刷新令牌 (Refresh token)
# ===========================================

# 从 Kiro IDE 流量中获取的刷新令牌
# Your Kiro refresh token obtained from Kiro IDE traffic
# REFRESH_TOKEN="your_kiro_refresh_token_here"

# ===========================================
# 选项 3: kiro-cli SQLite 数据库 (AWS SSO)
# ===========================================

# kiro-cli SQLite 数据库路径（适用于 AWS IAM Identity Center 用户）
# 网关将自动检测 AWS SSO OIDC 并使用正确的端点
# Path to kiro-cli SQLite database (for AWS IAM Identity Center users)
# KIRO_CLI_DB_FILE="~/.local/share/kiro-cli/data.sqlite3"

# ===========================================
# 选项 4: AWS SSO 缓存文件 (kiro-cli)
# ===========================================

# AWS SSO 缓存文件路径（包含 clientId 和 clientSecret）
# 网关将自动检测 AWS SSO OIDC 并使用正确的端点
# Path to AWS SSO cache file (contains clientId and clientSecret)
# KIRO_CREDS_FILE="~/.aws/sso/cache/your-sso-cache-file.json"

# ===========================================
# Profile ARN (可选)
# ===========================================

# AWS CodeWhisperer profile ARN
# Kiro IDE: 通常从凭证文件自动检测
# kiro-cli (AWS SSO / Builder ID): 不需要，将被忽略
# For Kiro IDE: usually auto-detected from credentials file
# PROFILE_ARN="arn:aws:codewhisperer:us-east-1:..."

# ===========================================
# 可选配置 (OPTIONAL)
# ===========================================

# AWS 区域（默认: us-east-1）
# AWS region (default: us-east-1)
KIRO_REGION="us-east-1"

# ===========================================
# 服务器设置 (SERVER SETTINGS)
# ===========================================

# 服务器监听地址（默认: 0.0.0.0 - 监听所有网络接口）
# 使用 "127.0.0.1" 仅允许本地连接
# Server host (default: 0.0.0.0 - listen on all interfaces)
SERVER_HOST="0.0.0.0"

# 服务器端口（默认: 8000）
# 当端口 8000 已被其他应用占用时很有用
# 配置优先级（从高到低）：
#   1. CLI 参数: python main.py --port 9000
#   2. 环境变量: SERVER_PORT=9000
#   3. 默认值: 8000
# Server port (default: 8000)
SERVER_PORT="9000"

# ===========================================
# VPN/代理设置 (VPN/PROXY SETTINGS)
# ===========================================

# VPN/代理 URL - 通过代理服务器访问 Kiro API
# 留空则直接连接（默认）
# 使用场景：
#   - 中国: GFW（防火长城）阻止 AWS 端点
#   - 企业网络: 通常需要强制代理
#   - 隐私: 向 AWS 隐藏你的 IP 地址
# 支持 HTTP 和 SOCKS5 协议，可在 URL 中嵌入认证信息
# VPN/Proxy URL for accessing Kiro API through a proxy server
# Examples:
#   VPN_PROXY_URL="http://127.0.0.1:7890"
#   VPN_PROXY_URL="socks5://127.0.0.1:1080"
VPN_PROXY_URL=""

# ===========================================
# 首个 Token 超时（流式重试）
# FIRST TOKEN TIMEOUT (Streaming Retry)
# ===========================================

# 等待模型首个 token 的超时时间（秒）
# 如果模型在此时间内未响应，请求将被取消并重试
# 默认: 15 秒（生产环境推荐）
# Timeout for waiting for the first token from the model (seconds)
FIRST_TOKEN_TIMEOUT="15"

# 首个 token 超时时的最大重试次数
# 耗尽所有尝试后，将返回 504 Gateway Timeout 错误
# 默认: 3 次
# Maximum number of retry attempts when first token timeout occurs
FIRST_TOKEN_MAX_RETRIES="3"

# 流式响应的读取超时时间（秒）
# 这是在流式传输期间等待数据块之间的最大时间
# 应该比 FIRST_TOKEN_TIMEOUT 更长，因为模型在"思考"时可能会暂停
# 默认: 300 秒（5 分钟）
# Read timeout for streaming responses (seconds)
STREAMING_READ_TIMEOUT="300"

# ===========================================
# 伪推理模式（通过标签注入实现扩展思考）
# FAKE REASONING (Extended Thinking via Tag Injection)
# ===========================================

# 启用伪推理 - 向请求注入特殊标签以启用模型推理
# 启用后，模型将在响应中包含其推理过程
# 响应将被解析并转换为 OpenAI 兼容的 reasoning_content 格式
# 默认: true（默认启用以获得开箱即用的高级体验）
# Enable fake reasoning - injects special tags into requests
FAKE_REASONING="true"

# 最大思考长度（tokens）
# 此值作为 <max_thinking_length>{value}</max_thinking_length> 注入到请求中
# 更高的值允许更详细的推理，但会增加响应时间和 token 使用量
# 默认: 4000 tokens
# Maximum thinking length in tokens
FAKE_REASONING_MAX_TOKENS="4000"

# 如何处理响应中的思考块：
# - "as_reasoning_content": 提取到 reasoning_content 字段（OpenAI 兼容，推荐）
# - "remove": 完全删除思考块，仅返回最终答案
# - "pass": 原样传递，保留原始标签在内容中
# - "strip_tags": 删除标签但保留思考内容在常规内容中
# 默认: "as_reasoning_content"
# How to handle the thinking block in responses
FAKE_REASONING_HANDLING="as_reasoning_content"

# 标签检测的初始缓冲区大小（字符）
# 解析器在决定响应是否包含思考标签之前缓冲这么多字符
# 较低的值 = 更快的首个 token 出现，但可能会遗漏带有前导空格的标签
# 默认: 20 字符
# Maximum size of initial buffer for tag detection (characters)
FAKE_REASONING_INITIAL_BUFFER_SIZE="20"

# ===========================================
# 截断恢复 (TRUNCATION RECOVERY)
# ===========================================

# 启用自动截断恢复 - 当 Kiro API 截断大型响应时
# 当模型生成大型工具调用或内容时，上游 API 可能会中途截断响应
# 此功能会自动通知模型截断情况，允许其调整方法
# 默认: true（默认启用以获得更好的开箱即用体验）
# Enable automatic truncation recovery when Kiro API cuts off large responses
TRUNCATION_RECOVERY="true"

# ===========================================
# 日志配置 (LOGGING)
# ===========================================

# 日志级别: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
# 默认: INFO（生产环境推荐）
# 设置为 DEBUG 以进行详细故障排除
# Log level (default: INFO for production)
LOG_LEVEL="DEBUG"

# ===========================================
# 调试模式（仅用于开发）
# DEBUG (for development only)
# ===========================================

# 调试日志模式：
# - off: 禁用（默认）
# - errors: 仅保存失败请求的日志（4xx, 5xx）- 推荐用于故障排除
# - all: 保存每个请求的日志（每次请求覆盖）
# Debug logging mode
DEBUG_MODE="off"

# 调试日志文件目录
# Directory for debug log files
DEBUG_DIR="debug_logs"

